{
  "hash": "e66b841cf5c29722a657452e35871c74",
  "result": {
    "markdown": "---\ntitle: \"Spotify With Machine Learning\"\ndescription: \"Exploring Spotify Music with Different Machine Learning Algorithms\"\nauthor:\n  - name: Erica Dale\n    url: http://ericamarie9016.githubt.io\n    affiliation: MEDS\n    affiliation-url: http://ucsb-meds.github.io\ndate: 2022-12-09\nformat:\n  html:\n    code-fold: false\n    code-summary: \"Show the code\"\ncode-overflow: wrap\ncode-block-bg: true\ncode-block-border-left: \"#6B5A75\"\ncategories: [MEDS, Machine Learning, R, Spotify, Music]\ncitation: \n  url: http://ericamarie9016.github.io/2023-02-22-spotify\nimage: music.jpeg\ndraft: TRUE\n---\n\n\n## Introduction\n\nThis fun project will use my personal Spotify music, along with my friend Kiran's, with the goal to build several machine learning algorithms that will determine whose music library a song belongs to. I will explore 4 candidate models (k nearest neighbors, decision trees, bagging, and random forest) to predict this binary outcome. To begin, the code to access your own Spotify account is included!\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(spotifyr)         # API interaction\nlibrary(here)             # Set file location\nlibrary(knitr)            # Creates nice tables\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(rsample)          # Creating and prepocessing machine learning models\nlibrary(readr)\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(rpart)\nlibrary(caret)\nlibrary(rpart.plot)\nlibrary(vip)\nlibrary(pdp)\nlibrary(parsnip)\nlibrary(ipred)\nlibrary(baguette)\n```\n:::\n\n\n### Access the Spotify API\n\nTo access the Spotify API, follow the link to \\<a href=\"https://developer.spotify.com\"\\>Spotify for Developers </a> and follow these instructions:\n\n-   Select \"Create a Client ID\"\n\n-   Fill out form to create an app\n\n-   On dashboard page, click new app\n\n-   App's dashboard page will have Client ID\n\n-   Click \"Show Client Secret\"\n\n-   Use the below code with your client ID and Client Secret in R!\n\n\n::: {.cell}\n\n```{.r .cell-code}\nSys.setenv(SPOTIFY_CLIENT_ID = 'your_token')\nSys.setenv(SPOTIFY_CLIENT_SECRET = 'your_token')\n \naccess_token <- get_spotify_access_token(\n   client_id = Sys.getenv(\"SPOTIFY_CLIENT_ID\"),\n   client_secret = Sys.getenv(\"SPOTIFY_CLIENT_SECRET\")\n)\n```\n:::\n\n\nI downloaded my liked songs, but the built-in function with the {spotifyr} package has a limit to download only 20 songs at a time. Below I wrote a loop to continue adding all of my liked songs into a dataframe.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsongs_data <- data.frame()     # create base empty data frame\noffset <- 0                    # starting point for spotify function offset\nlimit <- 20                    # maximum download at a time\n\nwhile(TRUE) {                  # loop through all liked songs\n\n  tracks <- get_my_saved_tracks(limit = limit, offset = offset)\n  \n  if(length(tracks) == 0) {    # setting when to stop the loop\n    break\n  }\n  \n  # add tracks into previously created dataframe\n  songs_data <- rbind(songs_data, tracks)  \n  \n  offset <- offset + limit     # reset the loop to start at the next 20\n\n}\n```\n:::\n\n\nThere are other functions to play with inside this {spotifyr} package! I will not be exploring these further in this blog post.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbearicas_recent <- get_my_recently_played()\nbearicas_top <- get_my_top_artists_or_tracks()\nunique(bearicas_top$genres)\n```\n:::\n\n\nThis initial data downloaded is not very exciting to play with. This data frame is mostly important to pull out the song ID column, and use that to connect back with Spotify's API for downloading the specific audio features for each song. This function has a maximum download of 100 rows at a time so I created another loop below to download all the related audio features and bind the columns to the initial dataframe.\n\n\n::: {.cell}\n\n```{.r .cell-code}\naudio_features <- data.frame()        # create base empty data frame\n\nfor(i in seq(from = 1, to = nrow(songs_data), by = 100)) { \n  \n  if (i > nrow(songs_data)) {         # setting when to stop the loop\n    break\n  }\n  \n  row_index <- i:(i + 99)             # collect 100 rows starting from i\n  \n  # pull out features for set rows\n  audio <- get_track_audio_features(songs_data$track.id[row_index])\n  \n  # add features to dataframe\n  audio_features <- rbind(audio_features, audio)\n}\n\n# will read in by 100, so may have NA's from the last loop\naudio_features <- drop_na(audio_features)\n\n# create data frame with songs and fun features!\nericas_audio <- cbind(audio_features, \n                      track.name = songs_data$track.name,\n                      track.popularity = songs_data$track.popularity) |> \n  select(-c(uri, track_href, analysis_url, type))     # remove rows\n  \n# save as csv to share\nwrite_csv(ericas_audio, \"ericas_audio.csv\")\n```\n:::\n\n\nMy friend Kiran and I swapped data, which I will use to create a series of machine learning models to compare our music tastes. The goal is to create a model that can predict, using the audio features whose playlist it is from. I will go through four different types of models and at the end compare the metrics of each to decide which was most effective! The outcome variable will be the binary option of Kiran or Erica, set as listener_id.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nericas_audio <- ericas_audio |> \n  mutate(listener_id = \"erica\")\n\nkirans_audio <- read_csv(\"kiran_audio.csv\") |>  # get partner's data as csv\n  mutate(listener_id = \"kiran\")\n\n# combine datasets\ntotal_audio <- rbind(ericas_audio, kirans_audio) |> \n  mutate(listener_id = as.factor(listener_id))\nwrite_csv(total_audio, \"total_audio.csv\")\n```\n:::\n\n\nAll of these previous steps culminate to this total_audio.csv file that I have previously saved and set aside, since I did not want to share my private Spotify information at the beginning.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntotal_audio <- read_csv(here(\"posts\", \"2023-02-22-spotify\", \"total_audio.csv\")) |> \n    mutate(listener_id = as.factor(listener_id))\n```\n:::\n\n\n### Data Exploration!\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\ntotal_audio %>%\n  arrange(desc(instrumentalness)) |> \n  select(instrumentalness, track.name, track.popularity, listener_id) |> \n  rename('track name' = track.name,\n         'track popularity' = track.popularity,\n         'listener' = listener_id) |> \n  head(6) |> \n  kable()\n```\n\n::: {.cell-output-display}\n| instrumentalness|track name                | track popularity|listener |\n|----------------:|:-------------------------|----------------:|:--------|\n|            0.971|Slow Blues - Instrumental |               38|kiran    |\n|            0.946|Orange                    |               42|kiran    |\n|            0.935|Ylang Ylang               |               61|kiran    |\n|            0.924|Atlas                     |               46|kiran    |\n|            0.924|Defect                    |               19|kiran    |\n|            0.918|Master Tea                |                0|erica    |\n:::\n:::\n\n\nSurprised to find out that the top instrumental songs belonged mostly to Kiran's playlist, I mostly listen to music with strong drums and little lyrics so expected that I'd be in the top.\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\ntotal_audio %>%\n  arrange(desc(acousticness)) |> \n  select(acousticness, track.name, track.popularity, listener_id) |> \n  rename('track name' = track.name,\n         'track popularity' = track.popularity,\n         'listener' = listener_id) |> \n  head(6) |> \n  kable()\n```\n\n::: {.cell-output-display}\n| acousticness|track name                       | track popularity|listener |\n|------------:|:--------------------------------|----------------:|:--------|\n|        0.994|Pachamama                        |               58|erica    |\n|        0.979|Flowers                          |               57|erica    |\n|        0.978|All We Do                        |               56|erica    |\n|        0.973|Whatever's Written in Your Heart |               29|kiran    |\n|        0.942|The Forsaken Waltz               |               32|kiran    |\n|        0.934|The View                         |                8|erica    |\n:::\n:::\n\n\nAlthough more of the top acoustic songs belonged in my playlist, Kiran listens to much louder music than me apparently.\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\nggplot(total_audio, aes(x = track.popularity, y = listener_id)) +\n  geom_boxplot(aes(fill = listener_id), color = \"#000000\", alpha = .8) +\n  labs(title = \"Distribution of Track Popularity by Listener\",\n       x = \"Track Popularity\", y = \"Listener\") +\n  scale_fill_manual(values = c(\"#9954FE\", \"#289832\")) +\n  theme_minimal() +\n  theme(plot.title = element_text(hjust = 0.5, face = \"bold\"),\n        panel.grid.minor = element_blank(),\n        panel.background = element_blank(),\n        axis.line = element_line(colour = \"black\"),\n        legend.position = \"none\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-10-1.png){width=672}\n:::\n:::\n\n\nI listen to the most music listed as 0 popularity, so maybe I'm more underground and edgy with my style.\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\nggplot(total_audio, aes(x = danceability, y = energy)) +\n  geom_point(aes(color = listener_id), alpha = .8, size = 2) +\n  labs(title = \"Comparison of Dancing Styles\",\n       x = \"Danceability\", y = \"Energy\") +\n  scale_color_manual(values = c(\"#9954FE\", \"#289832\"),\n                     labels = c(\"Erica\", \"Kiran\")) +\n  geom_text(x = .99, y = .97, label = \"Party Dancing\",\n            color = \"black\", size = 4, hjust = 1, vjust = 1) +\n  geom_text(x = 0.95, y = 0.2, label = \"Slow Dancing\",\n            color = \"black\", size = 3.5, hjust = 1, vjust = 0) +\n  geom_text(x = 0.2, y = 0.2, label = \"Chill Zone\",\n            color = \"black\", size = 3.5, hjust = 0, vjust = 0) +\n  theme_minimal() +\n  theme(plot.title = element_text(hjust = 0.5, face = \"bold\"),\n        panel.grid.minor = element_blank(),\n        axis.line = element_line(colour = \"black\"),\n        legend.position = \"bottom\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-11-1.png){width=672}\n:::\n:::\n\n\nWith this graph, low energy and high danceability would relate to slower (possibly romantic) songs, both of us appear to enjoy high energy and very danceable music but Kiran definitely goes harder.\n\n### Set Up Variables and Preprocessing\n\nI will be creating several machine learning models, and use these variables as the start for them all. This initial train/test split is an important step to divide the dataset in two subsets. The training data will be used throughout to build each model. The test data will only be used once for each model at the end to evaluate the performance of the model on before unseen data. Keeping the data separated avoids leakage, which happens when the final testing data has influence the building of the model.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(61234)                     # allows reproducibility\n\nsong_split <- initial_split(total_audio)\nsong_test <- testing(song_split) \nsong_train <- training(song_split)\n\n# Preprocessing, creating recipe with outcome and predictors\nsong_recipe <- recipe(listener_id ~ ., data = song_train) |> \n  \n  # Keep data but do not use are predictor\n  update_role(track.name, new_role = \"ID\") |>   \n  update_role(id, new_role = \"ID\") |> \n  step_rm(track.name, id) |> \n  \n  # Dummy code and normalize predictors\n  step_dummy(all_nominal(), -all_outcomes(), one_hot = TRUE) |> \n  step_normalize(all_numeric(), -all_outcomes()) |> \n  \n  prep()\n\n# Cross Validation to tune parameter\ncv_folds <- song_train |> \n  vfold_cv(v = 5)\n```\n:::\n\n\n### K Nearest Neighbors Model\n\nThis is a type of supervised machine learning algorithm used for classification and regression tasks. In this case, I will be using it as classification because we have the binary output variable of listener_id. When predicting the value of an input data point, this model looks for the \"K\" closest data points within the training set. The output prediction is based on the majority class or mean value of the K neighbors.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(45634)\n\n# Define nearest neighbor model\nknn_spec <- nearest_neighbor(neighbors = 7) |> \n  set_engine(\"kknn\") |> \n  set_mode(\"classification\")\n\n# Workflow\nknn_workflow <- workflow() |> \n  add_model(knn_spec) |> \n  add_recipe(song_recipe)\n\n# Fit resamples\nknn_res <- knn_workflow |> \n  fit_resamples(\n    resamples = cv_folds,\n    control = control_resamples(save_pred = TRUE))\n\n# Check Performance\nknn_res |> collect_metrics()\n\n# Tune the hyperparameters\nknn_spec_tune <- nearest_neighbor(neighbors = tune()) |> \n  set_engine(\"kknn\") |> \n  set_mode(\"classification\")\n\n# Workflow: Define new workflow\nknn_workflow_tune <- workflow() |> \n  add_model(knn_spec_tune) |> \n  add_recipe(song_recipe)\n\n# Fit workflow on predefined folds and hyperparameters\nknn_cv_fit <- knn_workflow_tune |> \n  tune_grid(\n    cv_folds,\n    grid = data.frame(neighbors = c(1, 5, seq(10, 100, 10))))\n\n# Check performance\nknn_cv_fit |> collect_metrics()\n# Results will show the n averaged over all the folds. Use this to predict the best\n\n# Workflow: Final\nknn_final_wf <- knn_workflow_tune |> \n  finalize_workflow(select_best(knn_cv_fit, metric = \"accuracy\"))\n\n# Fit: Final\nknn_final_fit <- knn_final_wf |> fit(data = song_train)\n\nknn_final_fit <- knn_final_wf |> last_fit(song_split)\n\nknn_metrics <- knn_final_fit |> collect_metrics()\n```\n:::\n\n\n### Decision Tree\n\nDecision tree models begin with all the data in a root node and making a split based on the most significant feature. Each split results in nodes of data to split on another feature, until there are finally no features left to split the data on. The model makes predictions by following the path from the root node to a leaf node following the rules set by each node split.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(346346)\n\n# dec tree specification tuned to the optimal parameters\ndec_tree_spec_tune <- decision_tree(\n  cost_complexity = tune(),\n  tree_depth = tune(),\n  min_n = tune()) |>\n   set_engine(\"rpart\") |>\n    set_mode(\"classification\")\n\ndec_tree_grid <- grid_regular(cost_complexity(),\n                          tree_depth(),\n                          min_n(),\n                          levels = 4)\n\ndoParallel::registerDoParallel()      # build trees in parallel\n\ndec_tree_rs <- tune_grid(\n  dec_tree_spec_tune,\n  listener_id ~ .,\n  resamples = cv_folds,\n  grid = dec_tree_grid,\n  metrics = metric_set(accuracy)\n)\n\nautoplot(dec_tree_rs) + theme_light()\n\ndec_final_tree <- finalize_model(dec_tree_spec_tune, \n                             select_best(dec_tree_rs))\n\nfinal_dectree_fit <- last_fit(dec_final_tree, \n                           listener_id ~ ., \n                           song_split)   # does training and testing runs\nfinal_dectree_fit$.predictions\n\ndtree_metrics <- final_dectree_fit |> collect_metrics()\n```\n:::\n\n\n### Bagging\n\nBagging is a form of bootstrap aggregation, this means that this is an ensemble model. The model constructs multiple versions of the same base model using random samples of the training data. All of these sub-models are aggregated into a final model. These steps improve the model performance by reducing variance and overfitting.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(4657345)\n\n# Tune specs\ntree_spec_tune <- bag_tree(\n  mode = \"classification\",\n  cost_complexity = tune(),\n  tree_depth = tune(),\n  min_n = tune()) |> \n  set_engine(\"rpart\", times = 50)\n\n# Define tree grid\ntree_grid <- grid_regular(cost_complexity(), tree_depth(), min_n(), levels = 5)\n\n# New workflow\nwf_tree_tune <- workflow() |> \n  add_recipe(song_recipe) |> \n  add_model(tree_spec_tune)\n\n\n# Build each model in parallel\ndoParallel::registerDoParallel()\n\n# Fit model\ntree_rs <- wf_tree_tune |>\n  tune_grid(listener_id ~ .,\n    resamples = cv_folds,\n    grid = tree_grid,\n    metrics = metric_set(accuracy))\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: The `...` are not used in this function but one or more objects were\npassed: ''\n```\n:::\n\n```{.r .cell-code}\ntree_rs |> collect_metrics()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 125 x 9\n   cost_complexity tree_depth min_n .metric  .esti~1  mean     n std_err .config\n             <dbl>      <int> <int> <chr>    <chr>   <dbl> <int>   <dbl> <chr>  \n 1    0.0000000001          1     2 accuracy binary  0.667     5  0.0336 Prepro~\n 2    0.0000000178          1     2 accuracy binary  0.665     5  0.0332 Prepro~\n 3    0.00000316            1     2 accuracy binary  0.667     5  0.0350 Prepro~\n 4    0.000562              1     2 accuracy binary  0.667     5  0.0350 Prepro~\n 5    0.1                   1     2 accuracy binary  0.665     5  0.0318 Prepro~\n 6    0.0000000001          4     2 accuracy binary  0.705     5  0.0249 Prepro~\n 7    0.0000000178          4     2 accuracy binary  0.722     5  0.0227 Prepro~\n 8    0.00000316            4     2 accuracy binary  0.716     5  0.0179 Prepro~\n 9    0.000562              4     2 accuracy binary  0.714     5  0.0204 Prepro~\n10    0.1                   4     2 accuracy binary  0.682     5  0.0318 Prepro~\n# ... with 115 more rows, and abbreviated variable name 1: .estimator\n```\n:::\n\n```{.r .cell-code}\n# Final workflow\nfinal_bag <- finalize_workflow(wf_tree_tune, select_best(tree_rs, \"accuracy\")) |> \n  fit(data = song_train)\n\n# Predictions\nbag_pred <- final_bag |> \n  predict(new_data = song_test) |> \n  bind_cols(song_test)\n\n# Output accuracy\nbag_metrics <- bag_pred |> \n  metrics(truth = listener_id, estimate = .pred_class)\n```\n:::\n\n\n### Random Forest\n\nRandom forest is another ensemble model, but this one cannot be done in parallel. This method creates multiple decision trees on random subsets of the data, and the key difference with this model is the random selection of features to include for each model. Not using all the features in each model then combining the decision trees improves the accuracy of the model.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Define validating set\nset.seed(1368)\nval_set <- validation_split(song_train, \n                            strata = listener_id, \n                            prop = 0.70)\n\n# Create Random Forest specification\nrf_spec <-\n  rand_forest(mtry = tune(),\n              min_n = tune(),\n              trees = 1000) %>%\n  set_engine(\"ranger\") %>%\n  set_mode(\"classification\")\n\n# Define Random Forest workflow\nrf_workflow <- workflow() %>%\n  add_recipe(song_recipe) %>%\n  add_model(rf_spec)\n\n# Build in parallel\ndoParallel::registerDoParallel()\nrf_res <- \n  rf_workflow %>% \n  tune_grid(val_set,\n            grid = 25,\n            control = control_grid(save_pred = TRUE),\n            metrics = metric_set(accuracy))\n```\n\n::: {.cell-output .cell-output-stderr}\n```\ni Creating pre-processing data to finalize unknown parameter: mtry\n```\n:::\n\n```{.r .cell-code}\n# Output model metrics\nrf_res %>% collect_metrics()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 25 x 8\n    mtry min_n .metric  .estimator  mean     n std_err .config              \n   <int> <int> <chr>    <chr>      <dbl> <int>   <dbl> <chr>                \n 1    13     5 accuracy binary     0.678     1      NA Preprocessor1_Model01\n 2    11    34 accuracy binary     0.720     1      NA Preprocessor1_Model02\n 3    14    23 accuracy binary     0.699     1      NA Preprocessor1_Model03\n 4     9    19 accuracy binary     0.678     1      NA Preprocessor1_Model04\n 5     8    38 accuracy binary     0.706     1      NA Preprocessor1_Model05\n 6     1    28 accuracy binary     0.664     1      NA Preprocessor1_Model06\n 7    12     6 accuracy binary     0.685     1      NA Preprocessor1_Model07\n 8     3    28 accuracy binary     0.692     1      NA Preprocessor1_Model08\n 9     2     7 accuracy binary     0.664     1      NA Preprocessor1_Model09\n10     7    12 accuracy binary     0.685     1      NA Preprocessor1_Model10\n# ... with 15 more rows\n```\n:::\n\n```{.r .cell-code}\n# Find the best accuracy metric\nrf_res %>% \n  show_best(metric = \"accuracy\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 5 x 8\n   mtry min_n .metric  .estimator  mean     n std_err .config              \n  <int> <int> <chr>    <chr>      <dbl> <int>   <dbl> <chr>                \n1    11    34 accuracy binary     0.720     1      NA Preprocessor1_Model02\n2    12    30 accuracy binary     0.720     1      NA Preprocessor1_Model18\n3     8    38 accuracy binary     0.706     1      NA Preprocessor1_Model05\n4    10    35 accuracy binary     0.706     1      NA Preprocessor1_Model20\n5    14    23 accuracy binary     0.699     1      NA Preprocessor1_Model03\n```\n:::\n\n```{.r .cell-code}\n# Plot results\nautoplot(rf_res) +\n  theme_minimal()\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-16-1.png){width=672}\n:::\n\n```{.r .cell-code}\n# Select best Random Forest model\nbest_rf <- select_best(rf_res, \"accuracy\")\nbest_rf\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 1 x 3\n   mtry min_n .config              \n  <int> <int> <chr>                \n1    11    34 Preprocessor1_Model02\n```\n:::\n\n```{.r .cell-code}\n# Output predictions\nrf_res %>% \n  collect_predictions()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 3,575 x 7\n   id         .pred_class  .row  mtry min_n listener_id .config              \n   <chr>      <fct>       <int> <int> <int> <fct>       <chr>                \n 1 validation kiran           3    13     5 erica       Preprocessor1_Model01\n 2 validation erica           8    13     5 erica       Preprocessor1_Model01\n 3 validation kiran          12    13     5 kiran       Preprocessor1_Model01\n 4 validation kiran          17    13     5 kiran       Preprocessor1_Model01\n 5 validation erica          20    13     5 erica       Preprocessor1_Model01\n 6 validation erica          22    13     5 kiran       Preprocessor1_Model01\n 7 validation kiran          28    13     5 kiran       Preprocessor1_Model01\n 8 validation erica          30    13     5 erica       Preprocessor1_Model01\n 9 validation kiran          31    13     5 kiran       Preprocessor1_Model01\n10 validation erica          36    13     5 erica       Preprocessor1_Model01\n# ... with 3,565 more rows\n```\n:::\n\n```{.r .cell-code}\n# Defining final model while working in parallel\ndoParallel::registerDoParallel()\nlast_rf_model <- \n  rand_forest(mtry = 2, min_n = 3, trees = 1000) %>% \n  set_engine(\"ranger\", importance = \"impurity\") %>% \n  set_mode(\"classification\")\n\n# Update workflow\nlast_rf_workflow <- \n  rf_workflow %>% \n  update_model(last_rf_model)\n\n# Update model fit\nlast_rf_fit <- \n  last_rf_workflow %>% \n  last_fit(song_split)\n\n# Output model metrics\nrandom_forest_metrics <- last_rf_fit %>% \n  collect_metrics()\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# Output the variables that are most important to our model\nlast_rf_fit %>% \n  extract_fit_parsnip() %>% \n  vip(num_features = 12) +\n  ggtitle(\"Variable Importance Plot\") +\n  theme(plot.title = element_text(hjust = 0.5)) +\n  theme_minimal()\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-17-1.png){width=672}\n:::\n:::\n\n\n\n### Comparing Metrics\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# nearest neighbors metrics\nknn_accuracy <- knn_metrics$.estimate[1]\n\n# decision tree metrics\n#dtree_accuracy <- dtree_metrics$.estimate[1]\n \n# bag tree metrics\nbag_accuracy <- bag_metrics$.estimate[1]\n\n# Random Forest metrics\nrf_accuracy <- random_forest_metrics$.estimate[1]\n\n\nmodel_accuracy <- tribble(\n  ~\"model\", ~\"accuracy\",\n  \"KNN\", knn_accuracy,\n#  \"Decision Tree\", dtree_accuracy,\n  \"Bagging\", bag_accuracy,\n  \"Random Forest\", rf_accuracy\n)\n\nggplot(data = model_accuracy, aes(x = model, y = accuracy)) +\n         geom_col() +\n  theme_minimal() +\n  labs(title = \"Comparison of Model Accuracy for Spotify Data\")\n```\n:::\n",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}
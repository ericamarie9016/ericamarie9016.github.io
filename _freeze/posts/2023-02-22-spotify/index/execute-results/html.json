{
  "hash": "410674bb098d52cdbb54d12e243b870d",
  "result": {
    "markdown": "---\ntitle: \"Spotify With Machine Learning\"\ndescription: \"Exploring Spotify Music with Different Machine Learning Algorithms\"\nauthor:\n  - name: Erica Dale\n    url: http://ericamarie9016.githubt.io\n    affiliation: MEDS\n    affiliation-url: http://ucsb-meds.github.io\ndate: 2022-12-09\nformat:\n  html:\n    code-fold: false\n    code-summary: \"Show the code\"\ncode-overflow: wrap\ncode-block-bg: true\ncode-block-border-left: \"#6B5A75\"\ncategories: [MEDS, Machine Learning, R, Spotify, Music]\ncitation: \n  url: http://ericamarie9016.github.io/2023-02-22-spotify\nimage: music.jpeg\ndraft: TRUE\n---\n\n\n## Introduction\n\nThis fun project will use my personal Spotify music, along with my friend Kiran's, with the goal to build several machine learning algorithms that will determine whose music library a song belongs to. I will explore 4 candidate models (k nearest neighbors, decision trees, bagging, and random forest) to predict this binary outcome. To begin, the code to access your own Spotify account is included!\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(spotifyr)         # API interaction\nlibrary(here)             # Set file location\nlibrary(knitr)      # Creates nice tables\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(readr)\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(rpart)\nlibrary(caret)\nlibrary(rpart.plot)\nlibrary(vip)\nlibrary(pdp)\nlibrary(parsnip)\nlibrary(ipred)\nlibrary(baguette)\n```\n:::\n\n\n### Access the Spotify API\n\nTo access the Spotify API, follow the link to \\<a href=\"https://developer.spotify.com\"\\>Spotify for Developers </a> and follow these instructions:\n\n-   Select \"Create a Client ID\"\n\n-   Fill out form to create an app\n\n-   On dashboard page, click new app\n\n-   App's dashboard page will have Client ID\n\n-   Click \"Show Client Secret\"\n\n-   Use the below code with your client ID and Client Secret in R!\n\n\n::: {.cell}\n\n```{.r .cell-code}\nSys.setenv(SPOTIFY_CLIENT_ID = 'your_token')\nSys.setenv(SPOTIFY_CLIENT_SECRET = 'your_token')\n \naccess_token <- get_spotify_access_token(\n   client_id = Sys.getenv(\"SPOTIFY_CLIENT_ID\"),\n   client_secret = Sys.getenv(\"SPOTIFY_CLIENT_SECRET\")\n)\n```\n:::\n\n\nI downloaded my liked songs, but the built-in function with the {spotifyr} package has a limit to download only 20 songs at a time. Below I wrote a loop to continue adding all of my liked songs into a dataframe.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsongs_data <- data.frame()     # create base empty data frame\noffset <- 0                    # starting point for spotify function offset\nlimit <- 20                    # maximum download at a time\n\nwhile(TRUE) {                  # loop through all liked songs\n\n  tracks <- get_my_saved_tracks(limit = limit, offset = offset)\n  \n  if(length(tracks) == 0) {    # setting when to stop the loop\n    break\n  }\n  \n  # add tracks into previously created dataframe\n  songs_data <- rbind(songs_data, tracks)  \n  \n  offset <- offset + limit     # reset the loop to start at the next 20\n\n}\n```\n:::\n\n\nThere are other functions to play with inside this {spotifyr} package! I will not be exploring these further in this blog post, but some examples I'm excited to explore are here.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbearicas_recent <- get_my_recently_played()\nbearicas_top <- get_my_top_artists_or_tracks()\nunique(bearicas_top$genres)\n```\n:::\n\n\nExploring the data frame was not very exciting, the columns had a lot of information that did not interest me and a lot of technical columns. This data frame is mostly important to pull out the song ID column, and use that to connect back with Spotify's API for downloading the specific audio features for each song. This function has a maximum download of 100 rows at a time so I created another loop below to download all the related audio features and bind the columns to the initial dataframe.\n\n\n::: {.cell}\n\n```{.r .cell-code}\naudio_features <- data.frame()        # create base empty data frame\n\nfor(i in seq(from = 1, to = nrow(songs_data), by = 100)) { \n  \n  if (i > nrow(songs_data)) {         # setting when to stop the loop\n    break\n  }\n  \n  row_index <- i:(i + 99)             # collect 100 rows starting from i\n  \n  # pull out features for set rows\n  audio <- get_track_audio_features(songs_data$track.id[row_index])\n  \n  # add features to dataframe\n  audio_features <- rbind(audio_features, audio)\n}\n\n# will read in by 100, so may have NA's from the last loop\naudio_features <- drop_na(audio_features)\n\n# create data frame with songs and fun features!\nericas_audio <- cbind(audio_features, \n                      track.name = songs_data$track.name,\n                      track.popularity = songs_data$track.popularity) |> \n  select(-c(uri, track_href, analysis_url, type))     # remove rows\n  \n# save as csv to share\nwrite_csv(ericas_audio, \"ericas_audio.csv\")\n```\n:::\n\n\nMy friend Kiran and I swapped data, which I will use to create a series of machine learning models to compare our music tastes. The goal is to create a model that can predict, using the audio features who is the listener. I would go through four different types of models and at the end compare the metrics of each to decide which was most effective! The outcome variable will be the binary option of Kiran or Erica, set as listener_id.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nericas_audio <- ericas_audio |> \n  mutate(listener_id = \"erica\")\n\nkirans_audio <- read_csv(\"kiran_audio.csv\") |>  # get partner's data as csv\n  mutate(listener_id = \"kiran\")\n\n# combine datasets\ntotal_audio <- rbind(ericas_audio, kirans_audio) |> \n  mutate(listener_id = as.factor(listener_id))\nwrite_csv(total_audio, \"total_audio.csv\")\n```\n:::\n\n\nAll of these previous steps culminate to this total_audio.csv file that I have previously saved and set aside, since I did not want to share my private Spotify information at the beginning.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntotal_audio <- read_csv(here(\"posts\", \"2023-02-22-spotify\", \"total_audio.csv\")) |> \n    mutate(listener_id = as.factor(listener_id))\n```\n:::\n\n\n### Data Exploration!\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntotal_audio %>%\n  arrange(desc(instrumentalness)) |> \n  select(instrumentalness, track.name, track.popularity, listener_id) |> \n  head(6) |> \n  kable()\n```\n\n::: {.cell-output-display}\n| instrumentalness|track.name                | track.popularity|listener_id |\n|----------------:|:-------------------------|----------------:|:-----------|\n|            0.971|Slow Blues - Instrumental |               38|kiran       |\n|            0.946|Orange                    |               42|kiran       |\n|            0.935|Ylang Ylang               |               61|kiran       |\n|            0.924|Atlas                     |               46|kiran       |\n|            0.924|Defect                    |               19|kiran       |\n|            0.918|Master Tea                |                0|erica       |\n:::\n:::\n\n\nSurprised to find out that the top instrumental songs belonged mostly to Kiran's playlist, I mostly listen to music with strong drums and little lyrics so expected that I'd be in the top.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntotal_audio %>%\n  arrange(desc(acousticness)) |> \n  select(acousticness, track.name, track.popularity, listener_id) |> \n  head(6) |> \n  kable()\n```\n\n::: {.cell-output-display}\n| acousticness|track.name                       | track.popularity|listener_id |\n|------------:|:--------------------------------|----------------:|:-----------|\n|        0.994|Pachamama                        |               58|erica       |\n|        0.979|Flowers                          |               57|erica       |\n|        0.978|All We Do                        |               56|erica       |\n|        0.973|Whatever's Written in Your Heart |               29|kiran       |\n|        0.942|The Forsaken Waltz               |               32|kiran       |\n|        0.934|The View                         |                8|erica       |\n:::\n:::\n\n\nAlthough more of the top acoustic songs belonged in my playlist, Kiran listens to much louder music than me apparently.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(total_audio, aes(x = track.popularity)) +\n  geom_bar(aes(fill = listener_id), alpha = .5) +\n  labs(title = \"Who Has More Popular Music Taste\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-10-1.png){width=672}\n:::\n:::\n\n\nI listen to the most music listed as 0 popularity, so maybe I'm more underground and edgy with my style.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(total_audio, aes(x = danceability, y = energy)) +\n  geom_point(aes(color = listener_id)) +\n  labs(title = \"Comparing Dancing Styles\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-11-1.png){width=672}\n:::\n:::\n\n\nWith this graph, low energy and high danceability would relate to slower (possibly romantic) songs, both of us appear to enjoy high energy and very danceable music but Kiran definitely goes harder.\n\n### Set Up Variables\n\nI will be creating several machine learning models, and use these variables as the start for them all.\n\nADD EXPLANATION OF TRAIN?TEST SPLIT\n\nAvoid leakage Train and test\nseparted, train data not used at all to influence test Split data before\npreprocessing - indirect form of leakage - Preprocessing is {tidymodels}\nfunctions like step - Create recipe, part of preprocessing\n\none_hot method of encoding categorical variable as numerical, turns column (genre) into series of columns for each and 0/1\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(14)                     # allows reproducibility\n\nsong_split <- initial_split(total_audio)\nsong_test <- testing(song_split) \nsong_train <- training(song_split)\n\n# Preprocessing\nsong_recipe <- recipe(listener_id ~ ., data = song_train) |> \n  update_role(track.name, new_role = \"ID\") |> \n  update_role(id, new_role = \"ID\") |> \n  step_dummy(all_nominal(), -all_outcomes(), one_hot = TRUE) |> \n  step_normalize(all_numeric(), -all_outcomes()) |> \n  prep()\n\n# Cross Validation to tune parameter\ncv_folds <- song_train |> \n  vfold_cv(v = 5)\n```\n:::\n\n\n### K Nearest Neighbors Model\n\nUnsure if update role above is working, getting errors\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Bake\n# NEVER USE THIS AGAIN?????\nknn_baked <- bake(song_recipe, song_train)\n\n# Apply recipe to test data\n# NEVER USE THIS AGAIN????\nknn_test <- bake(song_recipe, song_test)\n\n# Specify nearest neighbor model\nknn_spec <- nearest_neighbor(neighbors = 7) |> \n  set_engine(\"kknn\") |> \n  set_mode(\"classification\")\n\n# Workflow\nknn_workflow <- workflow() |> \n  add_model(knn_spec) |> \n  add_recipe(song_recipe)\n\n# Fit resamples\nknn_res <- knn_workflow |> \n  fit_resamples(\n    resamples = cv_folds,\n    control = control_resamples(save_pred = TRUE))\n\n# Check Performance\nknn_res |> collect_metrics()\n\n# Specify: Define model with tuning\n# Should I just do this the first time with spec, or run it again??\nknn_spec_tune <- nearest_neighbor(neighbors = tune()) |> \n  set_engine(\"kknn\") |> \n  set_mode(\"classification\")\n\n# Workflow: Define new workflow\n# Should I just skip the first spec/workflow??\nknn_workflow_tune <- workflow() |> \n  add_model(knn_spec_tune) |> \n  add_recipe(song_recipe)\n\n# Fit workflow on predefined folds and hyperparameters\nknn_cv_fit <- knn_workflow_tune |> \n  tune_grid(\n    cv_folds,\n    # Select other neighbors??\n    grid = data.frame(neighbors = c(1, 5, seq(10, 100, 10))))\n\n# Check performance\nknn_cv_fit |> collect_metrics()\n#Results will show the n averaged over all the folds. Use this to predict the best\n```\n:::\n\n\nPredict!\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Workflow: Final\nknn_final_wf <- knn_workflow_tune |> \n  finalize_workflow(select_best(knn_cv_fit, metric = \"accuracy\"))\n\n# Fit: Final\nknn_final_fit <- knn_final_wf |> fit(data = song_train)\n\nknn_final_fit <- knn_final_wf |> last_fit(song_split)\n\nknn_metrics <- knn_final_fit |> collect_metrics()\n```\n:::\n\n\n### Decision Tree\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# dec tree specification tuned to the optimal parameters\ndec_tree_spec_tune <- decision_tree(\n  cost_complexity = tune(),\n  tree_depth = tune(),\n  min_n = tune()) |>\n   set_engine(\"rpart\") |>\n    set_mode(\"classification\")\n\ndec_tree_grid <- grid_regular(cost_complexity(),\n                          tree_depth(),\n                          min_n(),\n                          levels = 4)\n\ndoParallel::registerDoParallel()      # build trees in parallel\n\ndec_tree_rs <- tune_grid(\n  dec_tree_spec_tune,\n  listener_id ~ .,\n  resamples = cv_folds,\n  grid = dec_tree_grid,\n  metrics = metric_set(accuracy)\n)\n\nautoplot(dec_tree_rs) + theme_light()\n\ndec_final_tree <- finalize_model(dec_tree_spec_tune, \n                             select_best(dec_tree_rs))\n\nfinal_dectree_fit <- last_fit(dec_final_tree, \n                           listener_id ~ ., \n                           song_split)   # does training and testing runs\nfinal_dectree_fit$.predictions\n\ndtree_metrics <- final_dectree_fit |> collect_metrics()\n```\n:::\n\n\n### Bagging\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Tune specs\ntree_spec_tune <- bag_tree(\n  mode = \"classification\",\n  cost_complexity = tune(),\n  tree_depth = tune(),\n  min_n = tune()) |> \n  set_engine(\"rpart\", times = 50)\n\n# Define tree grid\ntree_grid <- grid_regular(cost_complexity(), tree_depth(), min_n(), levels = 5)\n\n# New workflow\nwf_tree_tune <- workflow() |> \n  add_recipe(song_recipe) |> \n  add_model(tree_spec_tune)\n\n\n# Build in parallel\ndoParallel::registerDoParallel()\n\n# # fit model\ntree_rs <- wf_tree_tune |>\n  tune_grid(listener_id ~ .,\n    resamples = cv_folds,\n    grid = tree_grid,\n    metrics = metric_set(accuracy))\n\ntree_rs |> collect_metrics()\n\nfinal_bag <- finalize_workflow(wf_tree_tune, select_best(tree_rs, \"accuracy\")) |> \n  fit(data = song_train)\n\n# Predictions\nbag_pred <- final_bag |> \n  predict(new_data = song_test) |> \n  bind_cols(song_test)\n\n# Output accuracy\nbag_metrics <- bag_pred |> \n  metrics(truth = listener_id, estimate = .pred_class)\n\nbag_metrics\n```\n:::\n\n\n### Random Forest\n\n\n::: {.cell}\n\n```{.r .cell-code}\n## Defining validating set\nset.seed(123)\nval_set <- validation_split(song_train, \n                            strata = listener_id, \n                            prop = 0.70)\n\n## Creating Random Forest specification\nrf_spec <-\n  rand_forest(mtry = tune(),\n              min_n = tune(),\n              trees = 1000) %>%\n  set_engine(\"ranger\") %>%\n  set_mode(\"classification\")\n\n## Defining Random Forest workflow\nrf_workflow <- workflow() %>%\n  add_recipe(song_recipe) %>%\n  add_model(rf_spec)\n\n## Build in parallel\ndoParallel::registerDoParallel()\nrf_res <- \n  rf_workflow %>% \n  tune_grid(val_set,\n            grid = 25,\n            control = control_grid(save_pred = TRUE),\n            metrics = metric_set(accuracy))\n\n## Output model metrics\nrf_res %>% collect_metrics()\n\n## Find the best accuracy metric\nrf_res %>% \n  show_best(metric = \"accuracy\")\n\n## Plot results\nautoplot(rf_res)\n\n## Select best Random Forest model\nbest_rf <- select_best(rf_res, \"accuracy\")\nbest_rf\n\n## Output predictions\nrf_res %>% \n  collect_predictions()\n\n## Defining final model while working in parallel\ndoParallel::registerDoParallel()\nlast_rf_model <- \n  rand_forest(mtry = 2, min_n = 3, trees = 1000) %>% \n  set_engine(\"ranger\", importance = \"impurity\") %>% \n  set_mode(\"classification\")\n\n## Updating our workflow\nlast_rf_workflow <- \n  rf_workflow %>% \n  update_model(last_rf_model)\n\n## Updating our model fit\nset.seed(123)\nlast_rf_fit <- \n  last_rf_workflow %>% \n  last_fit(music_split)\n\n## Outputting model metrics\nrandom_forest_metrics <- last_rf_fit %>% \n  collect_metrics()\n\nrandom_forest_metrics\n\n## Outputting the variables that are most important to our model\nlast_rf_fit %>% \n  extract_fit_parsnip() %>% \n  vip::vip(num_features = 12) \n```\n:::\n\n\n### Comparing Metrics\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# # nearest neighbors metrics\nknn_accuracy <- knn_metrics$.estimate[1]\n# \n# # decision tree metrics\ndtree_accuracy <- dtree_metrics$.estimate[1]\n# \n# # bag tree metrics\nbag_accuracy <- bag_metrics$.estimate[1]\n\n# Random Forest metrics\nrf_accuracy <- random_forest_metrics$.estimate[1]\n\n\nmodel_accuracy <- tribble(\n  ~\"model\", ~\"accuracy\",\n  \"KNN\", knn_accuracy,\n  \"Decision Tree\", dtree_accuracy,\n  \"Bagging\", bag_accuracy,\n  \"Random Forest\", rf_accuracy\n)\n\nggplot(data = model_accuracy, aes(x = model, y = accuracy)) +\n         geom_col() +\n  theme_minimal() +\n  labs(title = \"Comparison of Model Accuracy for Spotify Data\")\n```\n:::\n",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}